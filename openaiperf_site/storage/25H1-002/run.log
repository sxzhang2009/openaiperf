2025-01-04T10:29:40Z [INFO] Starting OpenAIPerf evaluation...
2025-01-04T10:29:40Z [INFO] Configuration loaded: llm.generation task, offline scenario
2025-01-04T10:29:41Z [INFO] Initializing jax engine...
2025-01-04T10:29:43Z [INFO] Loading model: gemma-7b
2025-01-04T10:29:45Z [INFO] Model loaded successfully, dtype: fp8
2025-01-04T10:29:45Z [INFO] Quantization: AWQ enabled
2025-01-04T10:29:46Z [INFO] Starting inference server
2025-01-04T10:29:47Z [INFO] Beginning evaluation run (3 repeats)
2025-01-04T10:29:50Z [METRIC] Repeat 1/3 - Throughput: 1250.2 req/s
2025-01-04T10:29:53Z [METRIC] Repeat 2/3 - Throughput: 1251.2 req/s
2025-01-04T10:29:56Z [METRIC] Repeat 3/3 - Throughput: 1249.7 req/s
2025-01-04T10:29:56Z [RESULT] Final metrics - Throughput: 1250.2 req/s, P99 Latency: 45.3ms
2025-01-04T10:29:56Z [RESULT] Quality score: 78.9/100
2025-01-04T10:29:57Z [INFO] Evaluation completed successfully